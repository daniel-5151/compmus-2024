---
title: "Portfolio for Computational Musicology"
author: "DaniÃ«l Drucker"
output: 
  flexdashboard::flex_dashboard:
    storyboard: true
---

```{r setup, include=FALSE}
library(flexdashboard)
library(tidyverse)
library(spotifyr)
library(plotly)
library(knitr)
library(kableExtra)
library(compmus)
library(cowplot)
library(tidymodels)
library(ggdendro)
library(ranger)

get_conf_mat <- function(fit) {
  outcome <- .get_tune_outcome_names(fit)
  fit |> 
    collect_predictions() |> 
    conf_mat(truth = outcome, estimate = .pred_class)
}  

get_pr <- function(fit) {
  fit |> 
    conf_mat_resampled() |> 
    group_by(Prediction) |> mutate(precision = Freq / sum(Freq)) |> 
    group_by(Truth) |> mutate(recall = Freq / sum(Freq)) |> 
    ungroup() |> filter(Prediction == Truth) |> 
    select(class = Prediction, precision, recall)
}  
```

```{r load_playlists, include=FALSE}
playlist_beatles <- get_playlist_audio_features("", "18HKG7EtGQyvhL7t5lFXw6")
playlist_nirvana <- get_playlist_audio_features("", "0G935Lqu0vrEVoPNZNFrqP")
playlist_coldplay <- get_playlist_audio_features("", "1j08FQSS1hD36ldvdVXP3W") 

playlist_full <-
  bind_rows(
    playlist_beatles |> mutate(artist_name = "The Beatles"),
    playlist_nirvana |> mutate(artist_name = "Nirvana"),
    playlist_coldplay |> mutate(artist_name = "Coldplay")
  ) |>
  add_audio_analysis()
```

### Introduction
For the last few years my most listened to genre in my Spotify Wrapped has been Rock Music. Not surprising, since a large part of my personal playlists contain this genre. There is, however, a lot of subgenres within Rock. After it's quick rise of popularity in the 1960's, there have been a lot of different developments and movements. This is also the case in the music that I listen to, where there is a wide range of different subgenres. This got me thinking about what the differences between rock music in different time periods might be.  The main focus of this portfolio will be to uncover these differences within the limits of the Spotify API. We will do so by looking at a few different topics for different tracks. Examples of these will include track-level features, chroma features, different chords used and tempo.  

At first the plan was to look at rock as a whole for this comparison, but I soon found out that this would make the comparisons way to brought with all the different. This is why I narrowed the corpus down to three bands that each was very influential in their time: The Beatles in the 60's, Nirvana in the 80's/90's and Coldplay in the modern era. For each band I made a playlist based on the ones provided by Spotify. These include the most popular tracks. I then removed all the live tracks, since those can intervene with this research. The playlists can be found in the links below: 

- The Beatles: https://open.spotify.com/playlist/18HKG7EtGQyvhL7t5lFXw6?si=943a7297af884c30

- Nirvana: https://open.spotify.com/playlist/0G935Lqu0vrEVoPNZNFrqP?si=d99122f1223f407e

- Coldplay: https://open.spotify.com/playlist/1j08FQSS1hD36ldvdVXP3W?si=b0ec1bff23c644e1


Below are some interesting stats about the corpus for each band:
```{r introduction_table}
artist_stats <- playlist_full %>%
  group_by(artist_name) %>%
  summarise(num_entries = n(),
            total_duration = sum(track.duration_ms) / (1000 * 60),
            min_release_year = min(track.album.release_date),
            max_release_year = max(track.album.release_date))

artist_stats <- rename(artist_stats, "Band Name" = artist_name, 
                       "Number of Tracks" = num_entries,
                       "Total Duration (min)" = total_duration,
                       "First Album Release" = min_release_year,
                       "Last Album Release" = max_release_year)

kable(artist_stats) %>%
  kable_styling(full_width = FALSE, position = "left")
```

***
The Beatles:
<iframe style="border-radius:12px" src="https://open.spotify.com/embed/playlist/18HKG7EtGQyvhL7t5lFXw6?utm_source=generator&theme=0" width="100%" height="152" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture" loading="lazy"></iframe>

Nirvana:
<iframe style="border-radius:12px" src="https://open.spotify.com/embed/playlist/0G935Lqu0vrEVoPNZNFrqP?utm_source=generator" width="100%" height="152" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture" loading="lazy"></iframe>

Coldplay:
<iframe style="border-radius:12px" src="https://open.spotify.com/embed/playlist/1j08FQSS1hD36ldvdVXP3W?utm_source=generator&theme=0" width="100%" height="152" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture" loading="lazy"></iframe>

### What is the difference is tempo?
``` {r}
total_mean <- mean(playlist_full$tempo)
total_max <- max(playlist_full$tempo)
x_start = 0.5
y_start <- total_mean - 15
x_end <- 0.5
y_end <- total_mean


tempo <- playlist_full |>
  ggplot(aes(x = artist_name, y = tempo, fill = artist_name, alpha = 0.8)) +
  geom_boxplot() +
  geom_hline(yintercept = total_mean,
    color = "grey40", 
    linetype=3) +
  annotate(
    "text",
    x = x_start, y = y_start,
    label = "Total\naverage",
    vjust = 1, size = 3, color = "grey40"
  ) +
  annotate(
    "curve",
    x = x_start, y = y_start,
    xend = x_end, yend = y_end,
    arrow = arrow(length = unit(0.2, "cm"), type = "closed"),
    color = "grey40"
  ) +
  scale_y_continuous(     
    limits = c(0, total_max + 10),
    breaks = c(0, 50, 100, 150, 200),
    minor_breaks = NULL
  ) +
  theme_light() +
  theme(
    legend.position = "none",
    panel.grid.major.x = element_blank()
  ) +
  labs(
    x = "Band",
    y = "Tempo",
    title = "Tempo Distribution per Band"
  )

ggplotly(tempo)
```

***

The plot on the left shows how the bands differ in the tempo of their tracks. What strikes out first is that the tracks of Nirvana overall have a much higher tempo then both other bands. The median tempo of Nirvana is about 6.5% higher. This difference is even biggest in the top 50 percentile. This was expected beforehand, since Nirvana is known for its high energy music.

What was not expected however, is the great similarity of tempo of The Beatles and Coldplay. The boxplots of both bands on the left is near identical, where q1, q2 and the median are almost identical. It was expected beforehand that the difference in tempo would be a bit more noticeable. 

### Chromagram and Cepstrogram

```{r}
outlier <- "11LmqTE2naFULdEP94AUBa"

chroma <-
  get_tidy_audio_analysis(outlier) |>
  select(segments) |>
  unnest(segments) |>
  select(start, duration, pitches)

plot1a <-
  chroma |>
    mutate(pitches = map(pitches, compmus_normalise, "euclidean")) |>
    compmus_gather_chroma() |>
    ggplot(
      aes(
        x = start + duration / 2,
        width = duration,
        y = pitch_class,
        fill = value
      )
    ) +
    geom_tile() +
    labs(x = "Time (s)",
         y = NULL,
         fill = "Magnitude",
         title = "Chromogram (Heart Shaped Box - Nirvana)") +
    theme_minimal() +
    scale_fill_viridis_c()


chepstro <-
  get_tidy_audio_analysis(outlier) |>
  compmus_align(bars, segments) |>
  select(bars) |>
  unnest(bars) |>
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "rms", norm = "euclidean"
      )
  ) |>
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "rms", norm = "euclidean"
      )
  )

plot1b <-
  chepstro |>
    compmus_gather_timbre() |>
    ggplot(
      aes(
        x = start + duration / 2,
        width = duration,
        y = basis,
        fill = value
      )
    ) +
    geom_tile() +
    labs(
      x = "Time (s)",
      y = NULL,
      fill = "Magnitude",
      title = "Chepstrogram (Heart Shaped Box - Nirvana)") +
    scale_fill_viridis_c() +
    theme_classic()

plot_grid(plot1a, plot1b, ncol = 1)
```

***

### Self-Simularity Matrices
```{r}
max_popular_beatles <- playlist_beatles[which.max(playlist_beatles$track.popularity), ]
max_popular_nirvana <- playlist_nirvana[which.max(playlist_nirvana$track.popularity), ]
max_popular_coldplay <- playlist_coldplay[which.max(playlist_coldplay$track.popularity), ]

max_popular_nirvana_uri <- max_popular_nirvana$track.uri
max_popular_coldplay_uri <- max_popular_coldplay$track.uri

track1 <-
  get_tidy_audio_analysis("4CeeEOM32jQcH3eN9Q2dGj") |>
  compmus_align(bars, segments) |>
  select(bars) |>
  unnest(bars) |>
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "rms", norm = "euclidean"
      )
  ) |>
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "rms", norm = "euclidean"
      )
  )

track2 <-
  get_tidy_audio_analysis("3AJwUDP919kvQ9QcozQPxg") |>
  compmus_align(bars, segments) |>
  select(bars) |>
  unnest(bars) |>
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "rms", norm = "euclidean"
      )
  ) |>
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "rms", norm = "euclidean"
      )
  )

plot2a <-
  track1 |>
  compmus_self_similarity(pitches, "cosine") |>
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "", title = "Chroma (Smells Like Teen Spirit)")

plot2b <-
  track1 |>
  compmus_self_similarity(timbre, "cosine") |>
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "", title = "Timbre (Smells Like Teen Spirit)")

plot2c <-
  track2 |>
  compmus_self_similarity(pitches, "cosine") |>
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "", title = "Chroma (Yellow)")

plot2d <-
  track2 |>
  compmus_self_similarity(timbre, "cosine") |>
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "", title = "Timbre (Yellow)")

plot_grid(plot2a, plot2b, plot2c, plot2d, ncol = 2)

```

***


### Track-Level Analyses: Tempo, Volume and Duration
```{r}
playlist_full |>
  mutate(
    sections =
      map(
        sections,                                   
        summarise_at,
        vars(tempo, loudness, duration),            
        list(section_mean = mean, section_sd = sd)
      )
  ) |>
  unnest(sections) |>
  ggplot(
    aes(
      x = tempo,
      y = tempo_section_sd,
      colour = artist_name,
      alpha = loudness
    )
  ) +
  geom_point(aes(size = duration / 60)) +
  geom_rug() +
  theme_light() +
  ylim(0, 5) +
  labs(
    x = "Mean Tempo (bpm)",
    y = "SD Tempo",
    title = "Variation in Tempo",
    colour = "Band Name",
    size = "Duration (min)",
    alpha = "Volume (dBFS)"
  )
```

***
The plot on the left gives a more detailed look of the tempo graph made earlier. Here we can see that indeed tracks of Nirvana have a higher tempo and that the tracks of Coldplay and The Beatles are roughly equally distributed.

What is now also interesting to see is the standard deviation of the tempo for each track. There now seems to be a difference in tempo between The Beatles and Coldplay. According to the graph, The Beatles have more variation of tempo within their tracks then Coldplay. When we keep looking at the standard deviation of tempo, Nirvana seems to also be higher in this regard in comparison to the other two bands.

### Classifier
```{r include=FALSE}
artist_features <-
  playlist_full |>
  mutate(
    playlist = factor(artist_name),
    segments = map2(segments, key, compmus_c_transpose),
    pitches =
      map(
        segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      ),
    timbre =
      map(
        segments,
        compmus_summarise, timbre,
        method = "mean",
      )
  ) |>
  mutate(pitches = map(pitches, compmus_normalise, "clr")) |>
  mutate_at(vars(pitches, timbre), map, bind_rows) |>
  unnest(cols = c(pitches, timbre))
```


```{r include=FALSE}

artist_recipe <-
  recipe(
    playlist ~
      acousticness +
      instrumentalness +
      valence +
      duration +
      c02 + c05 + c06 + c11,
    data = artist_features
  ) |>
  step_center(all_predictors()) |>
  step_scale(all_predictors())

artist_cv <- artist_features |> vfold_cv(5)
```

```{r}
forest_model <-
  rand_forest() |>
  set_mode("classification") |> 
  set_engine("ranger", importance = "impurity")
artist_forest <- 
  workflow() |> 
  add_recipe(artist_recipe) |> 
  add_model(forest_model) |> 
  fit_resamples(
    artist_cv, 
    control = control_resamples(save_pred = TRUE)
  )

# artist_forest |> get_pr()

artist_forest |> get_conf_mat() |> autoplot(type = "mosaic")
```

***
The graph on the left shows the performance of a random-forest classifier trying to distinguish the three artists. Using all features, the most important are listed below:

- acousticness 

- instrumentalness

- valence 

- duration

The classifier also found that some of the chroma are important during classification: c02, c05, c06 and c11. All these features were used to train the random-forest classifier eventually used.

Overall, the classifier performs really well. 